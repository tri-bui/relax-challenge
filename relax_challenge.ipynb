{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relax Data Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies & data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 207917 entries, 0 to 207916\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   time_stamp  207917 non-null  datetime64[ns]\n",
      " 1   user_id     207917 non-null  int64         \n",
      " 2   visited     207917 non-null  int64         \n",
      "dtypes: datetime64[ns](1), int64(2)\n",
      "memory usage: 4.8 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>visited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-11-15 03:45:04</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           time_stamp  user_id  visited\n",
       "0 2014-04-22 03:53:30        1        1\n",
       "1 2013-11-15 03:45:04        2        1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage data\n",
    "usage_df = pd.read_csv('takehome_user_engagement.csv', parse_dates=['time_stamp'])\n",
    "print(usage_df.info())\n",
    "usage_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12000 entries, 0 to 11999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   object_id                   12000 non-null  int64         \n",
      " 1   creation_time               12000 non-null  datetime64[ns]\n",
      " 2   name                        12000 non-null  object        \n",
      " 3   email                       12000 non-null  object        \n",
      " 4   creation_source             12000 non-null  object        \n",
      " 5   last_session_creation_time  8823 non-null   float64       \n",
      " 6   opted_in_to_mailing_list    12000 non-null  int64         \n",
      " 7   enabled_for_marketing_drip  12000 non-null  int64         \n",
      " 8   org_id                      12000 non-null  int64         \n",
      " 9   invited_by_user_id          6417 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(4), object(3)\n",
      "memory usage: 937.6+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object_id</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>creation_source</th>\n",
       "      <th>last_session_creation_time</th>\n",
       "      <th>opted_in_to_mailing_list</th>\n",
       "      <th>enabled_for_marketing_drip</th>\n",
       "      <th>org_id</th>\n",
       "      <th>invited_by_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>Clausen August</td>\n",
       "      <td>AugustCClausen@yahoo.com</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>1.398139e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-11-15 03:45:04</td>\n",
       "      <td>Poole Matthew</td>\n",
       "      <td>MatthewPoole@gustr.com</td>\n",
       "      <td>ORG_INVITE</td>\n",
       "      <td>1.396238e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   object_id       creation_time            name                     email  \\\n",
       "0          1 2014-04-22 03:53:30  Clausen August  AugustCClausen@yahoo.com   \n",
       "1          2 2013-11-15 03:45:04   Poole Matthew    MatthewPoole@gustr.com   \n",
       "\n",
       "  creation_source  last_session_creation_time  opted_in_to_mailing_list  \\\n",
       "0    GUEST_INVITE                1.398139e+09                         1   \n",
       "1      ORG_INVITE                1.396238e+09                         0   \n",
       "\n",
       "   enabled_for_marketing_drip  org_id  invited_by_user_id  \n",
       "0                           0      11             10803.0  \n",
       "1                           0       1               316.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User data\n",
    "user_df = pd.read_csv('takehome_users.csv', parse_dates=['creation_time'], encoding='latin-1')\n",
    "print(user_df.info())\n",
    "user_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>creation_source</th>\n",
       "      <th>last_session_creation_time</th>\n",
       "      <th>opted_in_to_mailing_list</th>\n",
       "      <th>enabled_for_marketing_drip</th>\n",
       "      <th>org_id</th>\n",
       "      <th>invited_by_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>Clausen August</td>\n",
       "      <td>AugustCClausen@yahoo.com</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-11-15 03:45:04</td>\n",
       "      <td>Poole Matthew</td>\n",
       "      <td>MatthewPoole@gustr.com</td>\n",
       "      <td>ORG_INVITE</td>\n",
       "      <td>2014-03-31 03:45:04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>316.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       creation_time            name                     email  \\\n",
       "0        1 2014-04-22 03:53:30  Clausen August  AugustCClausen@yahoo.com   \n",
       "1        2 2013-11-15 03:45:04   Poole Matthew    MatthewPoole@gustr.com   \n",
       "\n",
       "  creation_source last_session_creation_time  opted_in_to_mailing_list  \\\n",
       "0    GUEST_INVITE        2014-04-22 03:53:30                         1   \n",
       "1      ORG_INVITE        2014-03-31 03:45:04                         0   \n",
       "\n",
       "   enabled_for_marketing_drip  org_id  invited_by_user_id  \n",
       "0                           0      11             10803.0  \n",
       "1                           0       1               316.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename `object_id` to `user_id`\n",
    "user_df.rename(columns={'object_id': 'user_id'}, inplace=True)\n",
    "\n",
    "# Convert `last_session_creation_time` to datetime\n",
    "user_df['last_session_creation_time'] = pd.to_datetime(user_df.last_session_creation_time, unit='s')\n",
    "user_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label adopted users and count usage for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1445\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>visited</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2014-04-17</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>2013-11-14</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    visited\n",
       "user_id time_stamp         \n",
       "1       2014-04-17        1\n",
       "2       2013-11-14        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group visits by each user's weekly visits\n",
    "weekly_usage_df = usage_df.groupby(['user_id', pd.Grouper(key='time_stamp', freq='7d')]).count()\n",
    "\n",
    "# Filter for users who visited at least 3 times during any week\n",
    "adopted_usage_df = weekly_usage_df[weekly_usage_df['visited'] >= 3]\n",
    "adopted_users = adopted_usage_df.index.get_level_values(0).unique().values\n",
    "\n",
    "print(len(adopted_users))\n",
    "weekly_usage_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>creation_source</th>\n",
       "      <th>last_session_creation_time</th>\n",
       "      <th>opted_in_to_mailing_list</th>\n",
       "      <th>enabled_for_marketing_drip</th>\n",
       "      <th>org_id</th>\n",
       "      <th>invited_by_user_id</th>\n",
       "      <th>adopted_user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>Clausen August</td>\n",
       "      <td>AugustCClausen@yahoo.com</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10803.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-11-15 03:45:04</td>\n",
       "      <td>Poole Matthew</td>\n",
       "      <td>MatthewPoole@gustr.com</td>\n",
       "      <td>ORG_INVITE</td>\n",
       "      <td>2014-03-31 03:45:04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       creation_time            name                     email  \\\n",
       "0        1 2014-04-22 03:53:30  Clausen August  AugustCClausen@yahoo.com   \n",
       "1        2 2013-11-15 03:45:04   Poole Matthew    MatthewPoole@gustr.com   \n",
       "\n",
       "  creation_source last_session_creation_time  opted_in_to_mailing_list  \\\n",
       "0    GUEST_INVITE        2014-04-22 03:53:30                         1   \n",
       "1      ORG_INVITE        2014-03-31 03:45:04                         0   \n",
       "\n",
       "   enabled_for_marketing_drip  org_id  invited_by_user_id  adopted_user  \n",
       "0                           0      11             10803.0             0  \n",
       "1                           0       1               316.0             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create label for adopted users\n",
    "# user_df['adopted_user'] = np.where(user_df['user_id'].isin(adopted_users), 1, 0)\n",
    "user_df['adopted_user'] = user_df['user_id'].isin(adopted_users).astype(int)\n",
    "assert user_df['adopted_user'].sum() == len(adopted_users) # confirm equal length\n",
    "user_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>creation_time</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>creation_source</th>\n",
       "      <th>last_session_creation_time</th>\n",
       "      <th>opted_in_to_mailing_list</th>\n",
       "      <th>enabled_for_marketing_drip</th>\n",
       "      <th>org_id</th>\n",
       "      <th>invited_by_user_id</th>\n",
       "      <th>adopted_user</th>\n",
       "      <th>visited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>Clausen August</td>\n",
       "      <td>AugustCClausen@yahoo.com</td>\n",
       "      <td>GUEST_INVITE</td>\n",
       "      <td>2014-04-22 03:53:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>10803.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-11-15 03:45:04</td>\n",
       "      <td>Poole Matthew</td>\n",
       "      <td>MatthewPoole@gustr.com</td>\n",
       "      <td>ORG_INVITE</td>\n",
       "      <td>2014-03-31 03:45:04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>316.0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id       creation_time            name                     email  \\\n",
       "0        1 2014-04-22 03:53:30  Clausen August  AugustCClausen@yahoo.com   \n",
       "1        2 2013-11-15 03:45:04   Poole Matthew    MatthewPoole@gustr.com   \n",
       "\n",
       "  creation_source last_session_creation_time  opted_in_to_mailing_list  \\\n",
       "0    GUEST_INVITE        2014-04-22 03:53:30                         1   \n",
       "1      ORG_INVITE        2014-03-31 03:45:04                         0   \n",
       "\n",
       "   enabled_for_marketing_drip  org_id  invited_by_user_id  adopted_user  \\\n",
       "0                           0      11             10803.0             0   \n",
       "1                           0       1               316.0             0   \n",
       "\n",
       "   visited  \n",
       "0        1  \n",
       "1       14  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a feature for the number of times each user logged in\n",
    "usage_count_df = usage_df.groupby('user_id', as_index=False).sum()\n",
    "user_df = user_df.merge(usage_count_df, on='user_id', how='left')\n",
    "user_df['visited'] = user_df['visited'].fillna(0).astype(int) # fill missing with 0\n",
    "user_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9000, 11), (3000, 11), (9000,), (3000,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split features and label\n",
    "X = user_df.drop('adopted_user', axis=1)\n",
    "y = user_df['adopted_user'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=25, stratify=y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7916\n",
       "1    1084\n",
       "Name: adopted_user, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class (im)balance\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9000 entries, 906 to 920\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   user_id                     9000 non-null   int64         \n",
      " 1   creation_time               9000 non-null   datetime64[ns]\n",
      " 2   name                        9000 non-null   object        \n",
      " 3   email                       9000 non-null   object        \n",
      " 4   creation_source             9000 non-null   object        \n",
      " 5   last_session_creation_time  6603 non-null   datetime64[ns]\n",
      " 6   opted_in_to_mailing_list    9000 non-null   int64         \n",
      " 7   enabled_for_marketing_drip  9000 non-null   int64         \n",
      " 8   org_id                      9000 non-null   int64         \n",
      " 9   invited_by_user_id          4843 non-null   float64       \n",
      " 10  visited                     9000 non-null   int64         \n",
      " 11  adopted_user                9000 non-null   int64         \n",
      "dtypes: datetime64[ns](2), float64(1), int64(6), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "def join_label_into_feats(X, y):\n",
    "    df = X.merge(y, left_index=True, right_index=True)\n",
    "    return df\n",
    "\n",
    "# Test function\n",
    "train = join_label_into_feats(X_train, y_train)\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9000, 12), (7916, 12), (1084, 12))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split train data by label\n",
    "train0 = train[train['adopted_user'] == 0].copy()\n",
    "train1 = train[train['adopted_user'] == 1].copy()\n",
    "train.shape, train0.shape, train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7916\n",
       "1    7916\n",
       "Name: adopted_user, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsample positive labels\n",
    "train1_resampled = train1.sample(train0.shape[0], replace=True, random_state=10)\n",
    "\n",
    "# Combine training data\n",
    "train_resampled = pd.concat([train0, train1_resampled]).reset_index(drop=True)\n",
    "train_resampled['adopted_user'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15832, 11), (15832,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split features and label\n",
    "X_train_resampled = train_resampled.drop('adopted_user', axis=1)\n",
    "y_train_resampled = train_resampled['adopted_user'].copy()\n",
    "X_train_resampled.shape, y_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15832, 11), (15832,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy train set for preprocessing\n",
    "X_train_preprocessed = X_train_resampled.copy()\n",
    "y_train_preprocessed = y_train_resampled.copy()\n",
    "X_train_preprocessed.shape, y_train_preprocessed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'usage_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cl/1tqm6ndx2bb8t04x6s1hdpzw0000gn/T/ipykernel_8835/3545448061.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a feature for each user's first day of use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfirst_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musage_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_stamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# save for feature pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train_resampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'first_use'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_resampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create a feature for the number of days between account creation and first use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'usage_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a feature for each user's first day of use\n",
    "first_use = dict(usage_df.groupby('user_id')['time_stamp'].min()) # save for feature pipeline\n",
    "X_train_resampled['first_use'] = X_train_resampled['user_id'].map(first_use)\n",
    "\n",
    "# Create a feature for the number of days between account creation and first use\n",
    "X_train_resampled['days_to_first_use'] = (X_train_resampled['first_use'] - X_train_resampled['creation_time']).dt.days\n",
    "X_train_resampled['days_to_first_use'].fillna(999, inplace=True)\n",
    "X_train_resampled['days_to_first_use'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a feature for same day use\n",
    "X_train_resampled['same_day_use'] = (X_train_resampled['days_to_first_use'] == 0).astype(int)\n",
    "X_train_resampled['same_day_use'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join label into features\n",
    "train_resampled = join_label_into_feats(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# User adoption rate of users who login within the first n days\n",
    "ar_1d = train_resampled[train_resampled['days_to_first_use'] < 1]['adopted_user'].mean()\n",
    "ar_7d = train_resampled[train_resampled['days_to_first_use'] < 7]['adopted_user'].mean()\n",
    "ar_30d = train_resampled[train_resampled['days_to_first_use'] < 30]['adopted_user'].mean()\n",
    "\n",
    "print(f'{ar_1d * 100:.2f}% of users who login within the same DAY as creating an account are adopted users.')\n",
    "print(f'{ar_7d * 100:.2f}% of users who login within the same WEEK as creating an account are adopted users.')\n",
    "print(f'{ar_30d * 100:.2f}% of users who login within the same MONTH as creating an account are adopted users.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check adoption rate of each signup month\n",
    "monthly_adoption_df = train_resampled.groupby(pd.Grouper(key='creation_time', freq='M'))[['adopted_user']].mean().reset_index()\n",
    "monthly_adoption_df['creation_time'] = monthly_adoption_df['creation_time'].dt.strftime('%Y-%m')\n",
    "monthly_adoption_df.columns = ['creation_month', 'adoption_rate']\n",
    "\n",
    "# Plot monthly adoption\n",
    "plt.figure(figsize=(16, 4))\n",
    "sns.lineplot(data=monthly_adoption_df, x='creation_month', y='adoption_rate')\n",
    "plt.title('Monthly Adoption Rate', fontsize=16)\n",
    "plt.xticks(ticks=range(monthly_adoption_df.shape[0]), labels=monthly_adoption_df['creation_month'], rotation=45, ha='right')\n",
    "plt.xlim((0, monthly_adoption_df.shape[0] - 1))\n",
    "\n",
    "monthly_adoption_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify `invited_by_user_id` to a boolean feature that indicates whether the user was invited\n",
    "X_train_resampled['invited'] = (X_train_resampled['invited_by_user_id'].notnull()).astype(int)\n",
    "\n",
    "# Extract email domain\n",
    "X_train_resampled['email_domain'] = X_train_resampled['email'].str.split('@', expand=True)[1]\n",
    "email_domains = X_train_resampled['email_domain'].value_counts()\n",
    "email_domains[email_domains > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group rare domains into a single category\n",
    "common_domains = email_domains[email_domains > 20].index.values # save for feature pipeline\n",
    "X_train_resampled['email_domain'] = X_train_resampled['email_domain'].apply(lambda d: d if d in common_domains else 'other')\n",
    "X_train_resampled['email_domain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join label into features\n",
    "train_resampled = join_label_into_feats(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# User adoption and average logins by email domain\n",
    "fig1, ax1 = plt.subplots(1, 2, figsize=(16, 4))\n",
    "sns.countplot(data=train_resampled, x='email_domain', hue='adopted_user', ax=ax1[0])\n",
    "sns.barplot(data=train_resampled, x='email_domain', y='visited', ax=ax1[1])\n",
    "ax1[0].set_title('User Adoption by Email Domain', fontsize=16)\n",
    "ax1[1].set_title('Average Logins by Email Domain', fontsize=16)\n",
    "ax1[0].set_xticklabels(ax1[0].get_xticklabels(), rotation=30, ha='right')\n",
    "ax1[1].set_xticklabels(ax1[1].get_xticklabels(), rotation=30, ha='right')\n",
    "\n",
    "# User adoption rate and average logins by email domain\n",
    "train_resampled.groupby('email_domain')[['adopted_user', 'visited']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User adoption and average logins by creation source\n",
    "fig2, ax2 = plt.subplots(1, 2, figsize=(16, 4))\n",
    "sns.countplot(data=train_resampled, x='creation_source', hue='adopted_user', ax=ax2[0])\n",
    "sns.barplot(data=train_resampled, x='creation_source', y='visited', ax=ax2[1])\n",
    "ax2[0].set_title('User Adoption by Creation Source', fontsize=16)\n",
    "ax2[1].set_title('Average Logins by Creation Source', fontsize=16)\n",
    "ax2[0].set_xticklabels(ax2[0].get_xticklabels(), rotation=30, ha='right')\n",
    "ax2[1].set_xticklabels(ax2[1].get_xticklabels(), rotation=30, ha='right')\n",
    "\n",
    "# User adoption rate and average logins by creation source\n",
    "user_df.groupby('creation_source')[['adopted_user', 'visited']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group organizations by size\n",
    "org_users = X_train_resampled['org_id'].value_counts()\n",
    "pd.qcut(org_users, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group organizations into 9 bins depending on size\n",
    "bin_size = 9\n",
    "org_cats = pd.qcut(org_users, bin_size, labels=range(bin_size)).to_dict() # save for feature pipeline\n",
    "X_train_resampled['org_size'] = X_train_resampled['org_id'].map(org_cats)\n",
    "\n",
    "# Group categories 0 and 1\n",
    "X_train_resampled.loc[X_train_resampled['org_size'] == 0, 'org_size'] = 1\n",
    "X_train_resampled['org_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join label into features\n",
    "train_resampled = join_label_into_feats(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Adoption rate by organization\n",
    "org_adoption_df = train_resampled.groupby('org_size')[['adopted_user', 'visited']].mean().sort_values('adopted_user', ascending=False)\n",
    "org_adoption_df['adopted_user'].plot(kind='barh', figsize=(8, 8))\n",
    "plt.title('Adoption Rate of Different Organization Size Classes', fontsize=16)\n",
    "plt.xlabel('adoption_rate')\n",
    "\n",
    "org_adoption_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an organization-to-adoption-rate mapping\n",
    "org_ar = org_adoption_df['adopted_user'].sort_index().to_dict() # save for feature pipeline\n",
    "print(org_ar)\n",
    "\n",
    "# Encode `org_id` with their adoption rate\n",
    "X_train_resampled['org_enc'] = X_train_resampled['org_size'].map(org_ar)\n",
    "X_train_resampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode creation_source\n",
    "src_ar = train_resampled.groupby('creation_source')['adopted_user'].mean().to_dict() # save for feature pipeline\n",
    "print(src_ar)\n",
    "\n",
    "# Encode `creation_source` with their adoption rate\n",
    "X_train_resampled['creation_enc'] = X_train_resampled['creation_source'].map(src_ar)\n",
    "X_train_resampled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode email_domain\n",
    "dom_ar = train_resampled.groupby('email_domain')['adopted_user'].mean().to_dict() # save for feature pipeline\n",
    "X_train_resampled['email_enc'] = X_train_resampled['email_domain'].map(dom_ar)\n",
    "X_train_resampled.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for train set\n",
    "selected_cols = ['creation_enc', 'email_enc', 'org_enc', 'invited', 'same_day_use', \n",
    "                 'opted_in_to_mailing_list', 'enabled_for_marketing_drip']\n",
    "X_train_preprocessed = X_train_resampled[selected_cols].copy()\n",
    "y_train_preprocessed = y_train_resampled.copy()\n",
    "\n",
    "X_train_preprocessed.shape, y_train_preprocessed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_pipeline(data, first_use_mapping, domain_list, domain_encoding, \n",
    "                     org_bins, org_encoding, source_encoding, selected_features):\n",
    "    \n",
    "    \"\"\"\n",
    "    Feature pipeline:\n",
    "    - same_day_use\n",
    "        > first_use (encode user_id w/ `first_use`) \n",
    "        > days_to_first_use (diff first_use and creation_time in days, fill na w/ 999) \n",
    "        > same_day_use (binary encode days_to_first_use)\n",
    "    - invited (binary encode invited_by_user_id)\n",
    "    - email_enc\n",
    "        > email_domain (extract domain from email, rare-category encode email_domain w/ `common_domains`) \n",
    "        > email_enc (mean-target encode email_domain w/ `dom_ar`)\n",
    "    - org_enc\n",
    "        > org_size (bin org_id value counts w/ `org_cats`, combine bins 0 and 1)\n",
    "        > org_enc (mean-target encode org_size w/ `org_ar`)\n",
    "    - creation_enc (mean-target encode creation_source w/ `src_ar`)\n",
    "    - select features: 'creation_enc', 'email_enc', 'org_enc', 'invited', 'same_day_use', \n",
    "                       'opted_in_to_mailing_list', 'enabled_for_marketing_drip'\n",
    "    \"\"\"\n",
    "    \n",
    "    data = data.copy()\n",
    "    \n",
    "    # Create binary feature for same day use\n",
    "    data['first_use'] = data['user_id'].map(first_use_mapping) # first day of use\n",
    "    data['days_to_first_use'] = (data['first_use'] - data['creation_time']).dt.days # number of days to first use\n",
    "    data['days_to_first_use'].fillna(999, inplace=True)\n",
    "    data['same_day_use'] = (data['days_to_first_use'] == 0).astype(int)\n",
    "    \n",
    "    # Create a binary feature for invited\n",
    "    data['invited'] = (data['invited_by_user_id'].notnull()).astype(int)\n",
    "    \n",
    "    # Encode email domains with their adoption rates\n",
    "    data['email_domain'] = data['email'].str.split('@', expand=True)[1] # email domain\n",
    "    data['email_domain'] = data['email_domain'].apply(lambda d: d if d in domain_list else 'other') # encode rare categories\n",
    "    data['email_enc'] = data['email_domain'].map(domain_encoding)\n",
    "    \n",
    "    # Encode organization sizes with their adoption rates\n",
    "    data['org_size'] = data['org_id'].map(org_bins) # group organizations into 9 bins\n",
    "    data.loc[data['org_size'] == 0, 'org_size'] = 1 # group bins 0 and 1\n",
    "    data['org_enc'] = data['org_size'].map(org_encoding)\n",
    "\n",
    "    # Encode creation sources with their adoption rates\n",
    "    data['creation_enc'] = data['creation_source'].map(source_encoding)\n",
    "    \n",
    "    # Select features\n",
    "    data = data[selected_features].copy()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "# Test pipeline\n",
    "X_test_preprocessed = feature_pipeline(X_test, first_use, common_domains, dom_ar, org_cats, org_ar, src_ar, selected_cols)\n",
    "y_test_preprocessed = y_test.copy()\n",
    "X_test_preprocessed.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr = LogisticRegression(max_iter=1e4, random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred_train = lr.predict(X_train)\n",
    "lr_pred_test = lr.predict(X_test)\n",
    "\n",
    "print('Train')\n",
    "print('Accuracy:', lr.score(X_train, y_train))\n",
    "print('ROC AUC:', roc_auc_score(y_train, lr_pred_train))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_train, lr_pred_train))\n",
    "\n",
    "print('\\nTest')\n",
    "print('Accuracy:', lr.score(X_test, y_test))\n",
    "print('ROC AUC:', roc_auc_score(y_test, lr_pred_test))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, lr_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree grid search\n",
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "params = {'max_depth': range(2, 22, 2), 'min_samples_split': range(2, 22, 2), 'min_samples_leaf': range(2, 22, 2)}\n",
    "gs = GridSearchCV(dt, params, scoring='roc_auc', cv=5, n_jobs=10)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "dt = gs.best_estimator_\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred_train = dt.predict(X_train)\n",
    "dt_pred_test = dt.predict(X_test)\n",
    "\n",
    "print('Train')\n",
    "print('Score:', dt.score(X_train, y_train))\n",
    "print('ROC AUC:', roc_auc_score(y_train, dt_pred_train))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_train, dt_pred_train))\n",
    "\n",
    "print('\\nTest')\n",
    "print('Score:', dt.score(X_test, y_test))\n",
    "print('ROC AUC:', roc_auc_score(y_test, dt_pred_test))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, dt_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature coefficients\n",
    "pd.DataFrame(np.array([X_train.columns.values, lr.coef_[0], dt.feature_importances_]).T, \n",
    "             columns=['feature', 'lr_coef', 'dt_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Modeling 2 (with resampled data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data by label\n",
    "train = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\n",
    "train0 = train[train['adopted_user'] == 0]\n",
    "train1 = train[train['adopted_user'] == 1]\n",
    "train.shape, train0.shape, train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample positive labels\n",
    "train1_resampled = train1.sample(train0.shape[0], replace=True)\n",
    "\n",
    "# Combine training data\n",
    "train_resampled = pd.concat([train0, train1_resampled])\n",
    "train_resampled['adopted_user'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and label\n",
    "X_train_resampled = train_resampled.drop('adopted_user', axis=1).copy()\n",
    "y_train_resampled = train_resampled['adopted_user'].copy()\n",
    "X_train_resampled.shape, y_train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr_resampled = LogisticRegression(max_iter=1e4, random_state=0)\n",
    "lr_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "lr_resampled_pred_train = lr_resampled.predict(X_train_resampled)\n",
    "lr_resampled_pred_test = lr_resampled.predict(X_test)\n",
    "\n",
    "print('Train')\n",
    "print('Accuracy:', lr_resampled.score(X_train_resampled, y_train_resampled))\n",
    "print('ROC AUC:', roc_auc_score(y_train_resampled, lr_resampled_pred_train))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_train_resampled, lr_resampled_pred_train))\n",
    "\n",
    "print('\\nTest')\n",
    "print('Accuracy:', lr_resampled.score(X_test, y_test))\n",
    "print('ROC AUC:', roc_auc_score(y_test, lr_resampled_pred_test))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, lr_resampled_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree grid search\n",
    "dt_resampled = DecisionTreeClassifier(random_state=0)\n",
    "params_resampled = {'max_depth': range(2, 22, 2), 'min_samples_split': range(2, 22, 2), 'min_samples_leaf': range(2, 22, 2)}\n",
    "gs_resampled = GridSearchCV(dt_resampled, params_resampled, scoring='roc_auc', cv=5, n_jobs=10)\n",
    "gs_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(gs_resampled.best_score_)\n",
    "print(gs_resampled.best_params_)\n",
    "gs_resampled.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "dt_resampled = gs_resampled.best_estimator_\n",
    "dt_resampled.fit(X_train_resampled, y_train_resampled)\n",
    "dt_resampled_pred_train = dt_resampled.predict(X_train_resampled)\n",
    "dt_resampled_pred_test = dt_resampled.predict(X_test)\n",
    "\n",
    "print('Train')\n",
    "print('Score:', dt_resampled.score(X_train_resampled, y_train_resampled))\n",
    "print('ROC AUC:', roc_auc_score(y_train_resampled, dt_resampled_pred_train))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_train_resampled, dt_resampled_pred_train))\n",
    "\n",
    "print('\\nTest')\n",
    "print('Score:', dt_resampled.score(X_test, y_test))\n",
    "print('ROC AUC:', roc_auc_score(y_test, dt_resampled_pred_test))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, dt_resampled_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature coefficients\n",
    "pd.DataFrame(np.array([X_train_resampled.columns.values, lr_resampled.coef_[0], dt_resampled.feature_importances_]).T, \n",
    "             columns=['feature', 'lr_coef', 'dt_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling 3 (with a binary feature subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for binary features\n",
    "X_train_bin = X_train_resampled[['invited', 'mailing_list', 'marketing_drip']].copy()\n",
    "X_test_bin = X_test[['invited', 'mailing_list', 'marketing_drip']].copy()\n",
    "X_train_bin.shape, X_test_bin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr_bin = LogisticRegression(max_iter=1e4, random_state=0)\n",
    "lr_bin.fit(X_train_bin, y_train_resampled)\n",
    "lr_bin_pred_train = lr_bin.predict(X_train_bin)\n",
    "lr_bin_pred_test = lr_bin.predict(X_test_bin)\n",
    "\n",
    "print('Train')\n",
    "print('Accuracy:', lr_bin.score(X_train_bin, y_train_resampled))\n",
    "print('ROC AUC:', roc_auc_score(y_train_resampled, lr_bin_pred_train))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_train_resampled, lr_bin_pred_train))\n",
    "\n",
    "print('\\nTest')\n",
    "print('Accuracy:', lr_bin.score(X_test_bin, y_test))\n",
    "print('ROC AUC:', roc_auc_score(y_test, lr_bin_pred_test))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, lr_bin_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree grid search\n",
    "dt_bin = DecisionTreeClassifier(random_state=0)\n",
    "params_bin = {'max_depth': range(2, 22, 2), 'min_samples_split': range(2, 22, 2), 'min_samples_leaf': range(2, 22, 2)}\n",
    "gs_bin = GridSearchCV(dt_bin, params_bin, scoring='roc_auc', cv=5, n_jobs=10)\n",
    "gs_bin.fit(X_train_bin, y_train_resampled)\n",
    "\n",
    "print(gs_bin.best_score_)\n",
    "print(gs_bin.best_params_)\n",
    "gs_bin.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "dt_bin = gs_bin.best_estimator_\n",
    "dt_bin.fit(X_train_bin, y_train_resampled)\n",
    "dt_bin_pred_train = dt_bin.predict(X_train_bin)\n",
    "dt_bin_pred_test = dt_bin.predict(X_test_bin)\n",
    "\n",
    "print('Train')\n",
    "print('Score:', dt_bin.score(X_train_bin, y_train_resampled))\n",
    "print('ROC AUC:', roc_auc_score(y_train_resampled, dt_bin_pred_train))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_train_resampled, dt_bin_pred_train))\n",
    "\n",
    "print('\\nTest')\n",
    "print('Score:', dt_bin.score(X_test_bin, y_test))\n",
    "print('ROC AUC:', roc_auc_score(y_test, dt_bin_pred_test))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, dt_bin_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature coefficients\n",
    "pd.DataFrame(np.array([X_train_bin.columns.values, lr_bin.coef_[0], dt_bin.feature_importances_]).T, \n",
    "             columns=['feature', 'lr_coef', 'dt_coef'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling 4 (with encoded feature subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for encoded features\n",
    "X_train_enc = X_train_resampled[['creation_encoding', 'domain_encoding', 'org_encoding']].copy()\n",
    "X_test_enc = X_test[['creation_encoding', 'domain_encoding', 'org_encoding']].copy()\n",
    "X_train_enc.shape, X_test_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "lr_enc = LogisticRegression(max_iter=1e4, random_state=0)\n",
    "lr_enc.fit(X_train_enc, y_train_resampled)\n",
    "lr_enc_pred_train = lr_enc.predict(X_train_enc)\n",
    "lr_enc_pred_test = lr_enc.predict(X_test_enc)\n",
    "\n",
    "print('Train')\n",
    "print('Accuracy:', lr_enc.score(X_train_enc, y_train_resampled))\n",
    "print('ROC AUC:', roc_auc_score(y_train_resampled, lr_enc_pred_train))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_train_resampled, lr_enc_pred_train))\n",
    "\n",
    "print('\\nTest')\n",
    "print('Accuracy:', lr_enc.score(X_test_enc, y_test))\n",
    "print('ROC AUC:', roc_auc_score(y_test, lr_enc_pred_test))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, lr_enc_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree grid search\n",
    "dt_enc = DecisionTreeClassifier(random_state=0)\n",
    "params_enc = {'max_depth': range(2, 22, 2), 'min_samples_split': range(2, 22, 2), 'min_samples_leaf': range(2, 22, 2)}\n",
    "gs_enc = GridSearchCV(dt_enc, params_enc, scoring='roc_auc', cv=5, n_jobs=10)\n",
    "gs_enc.fit(X_train_enc, y_train_resampled)\n",
    "\n",
    "print(gs_enc.best_score_)\n",
    "print(gs_enc.best_params_)\n",
    "gs_enc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree\n",
    "dt_enc = gs_enc.best_estimator_\n",
    "dt_enc.fit(X_train_enc, y_train_resampled)\n",
    "dt_enc_pred_train = dt_enc.predict(X_train_enc)\n",
    "dt_enc_pred_test = dt_enc.predict(X_test_enc)\n",
    "\n",
    "print('Train')\n",
    "print('Score:', dt_enc.score(X_train_enc, y_train_resampled))\n",
    "print('ROC AUC:', roc_auc_score(y_train_resampled, dt_enc_pred_train))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_train_resampled, dt_enc_pred_train))\n",
    "\n",
    "print('\\nTest')\n",
    "print('Score:', dt_enc.score(X_test_enc, y_test))\n",
    "print('ROC AUC:', roc_auc_score(y_test, dt_enc_pred_test))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, dt_enc_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature coefficients\n",
    "pd.DataFrame(np.array([X_train_enc.columns.values, lr_enc.coef_[0], dt_enc.feature_importances_]).T, \n",
    "             columns=['feature', 'lr_coef', 'dt_coef'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
